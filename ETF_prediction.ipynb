{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pymongo import MongoClient\n",
    "from Tbrain_service import DataPreproecss\n",
    "from Tbrain_service import DataVisualization\n",
    "from Tbrain_service import Util\n",
    "from Tbrain_service import Evaluation\n",
    "from Tbrain_service import FeatureExtraction\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from xgboost import XGBRegressor\n",
    "from keras.layers import LSTM, GRU, Dense, TimeDistributed\n",
    "from keras.models import Sequential\n",
    "from stockstats import StockDataFrame\n",
    "from keras.callbacks import EarlyStopping\n",
    "from fbprophet import Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_linear_regression(etf_df):\n",
    "    dp = DataPreproecss()\n",
    "    train_df = dp.trans_time_series_to_supervised(etf_df, 5, 'adj close')\n",
    "    print(\"linear_regression train df shape: {}\".format(train_df.shape))\n",
    "    \n",
    "    train_X = train_df.loc[:,train_df.columns!='y']\n",
    "    train_y = train_df.loc[:,train_df.columns=='y']\n",
    "    \n",
    "    train_X_scale, scaler_X = dp.standardize(train_X)\n",
    "    train_y_scale, scaler_y = dp.standardize(train_y)\n",
    "\n",
    "    # test data\n",
    "    test_X = etf_df.iloc[-5:]\n",
    "    test_X_scale = scaler_X.transform(test_X)\n",
    "    model = LinearRegression()\n",
    "    model.fit(train_X_scale, train_y_scale)\n",
    "    pred = scaler_y.inverse_transform(model.predict(test_X_scale)).flatten()\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_xgboost(etf_df):\n",
    "    dp = DataPreproecss()\n",
    "    train_df = dp.trans_time_series_to_supervised(etf_df, 5, 'adj close')\n",
    "    train_X = train_df.loc[:,train_df.columns!='y']\n",
    "    train_y = train_df.loc[:,train_df.columns=='y']\n",
    "    \n",
    "    train_X_scale, scaler_X = dp.standardize(train_X)\n",
    "    train_y_scale, scaler_y = dp.standardize(train_y)\n",
    "    \n",
    "    # test data\n",
    "    test_X = etf_df.iloc[-5:]\n",
    "    test_X_scale = scaler_X.transform(test_X)\n",
    "    model = XGBRegressor()\n",
    "    model.fit(train_X_scale, train_y_scale)\n",
    "    pred = scaler_y.inverse_transform(model.predict(test_X_scale)).flatten()\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_ARIMA(etf_df):\n",
    "    train_series = etf_df.loc[:,['adj close']]\n",
    "    # arima p, d, and q parameters\n",
    "    model = ARIMA(train_series, order=(5,0,0))  \n",
    "    model = model.fit()\n",
    "    start_index = len(train_series) - 1\n",
    "    end_index = len(train_series) - 1 + 4\n",
    "    pred = model.predict(start_index, end_index, dynamic= True)\n",
    "    pred = np.array(pred)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_prophet(etf_df):\n",
    "    df = pd.DataFrame()\n",
    "    df['ds'] = etf_df.index\n",
    "    df['y'] = etf_df['adj close'].values\n",
    "    m = Prophet()\n",
    "    m.fit(df)\n",
    "    future = m.make_future_dataframe(periods=5)\n",
    "    pred = m.predict(future).tail(5)['yhat'].values\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_RNN_many_to_many(etf_df):\n",
    "    dp = DataPreproecss()\n",
    "    time_step = 5\n",
    "    etf_df = etf_df.loc[:,['adj close']]\n",
    "    etf_df_window = dp.make_slide_windows(etf_df, time_step * 2)\n",
    "    train_X = etf_df_window.iloc[:,:time_step]\n",
    "    train_X_scale, scaler_X = dp.standardize(train_X)\n",
    "    train_y = etf_df_window.iloc[:,-time_step:]\n",
    "    train_y_scale, scaler_y = dp.standardize(train_y)\n",
    "    # 最先一週\n",
    "    test_X_scale = scaler_X.transform(etf_df_window.iloc[-1:,-time_step:])\n",
    "    # reshape\n",
    "    train_X_scale = train_X_scale.reshape(len(train_X_scale), time_step, 1)\n",
    "    train_y_scale = train_y_scale.reshape(len(train_X_scale), time_step, 1)\n",
    "    test_X_scale = test_X_scale.reshape(len(test_X_scale), time_step, 1)\n",
    "    print(\"train_X_scale: {}, train_y_scale: {}, test_X_scale: {}\".format(train_X_scale.shape, train_y_scale.shape, test_X_scale.shape))\n",
    "    # train model\n",
    "    model = Sequential()\n",
    "    model.add(GRU(20, input_shape=(time_step, 1), return_sequences=True))\n",
    "    model.add(GRU(20, return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(1)))\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    model.summary()\n",
    "    model.fit(\n",
    "        train_X_scale, train_y_scale, \n",
    "        epochs=50, batch_size=32, verbose=1, \n",
    "        validation_split=0.2)\n",
    "    # predict\n",
    "    pred = model.predict(test_X_scale)\n",
    "    pred = pred.reshape(1, 5)\n",
    "    pred = scaler_y.inverse_transform(pred).flatten()\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_RNN_many_to_one(etf_df):\n",
    "    dp = DataPreproecss()\n",
    "    feature_num = etf_df.shape[1]\n",
    "    shift_range = 5\n",
    "    time_step = 20\n",
    "    etf_df_supervised = dp.trans_time_series_to_supervised(etf_df, shift_range, 'adj close')\n",
    "\n",
    "    train_X = etf_df_supervised.loc[:, etf_df_supervised.columns!='y']\n",
    "    train_y = etf_df_supervised.loc[:, etf_df_supervised.columns=='y']\n",
    "\n",
    "    train_X = dp.make_slide_windows(train_X, time_step)\n",
    "    train_y = train_y[time_step-1:]\n",
    "\n",
    "    train_X_scale, scaler_X = dp.standardize(train_X)\n",
    "    train_y_scale, scaler_y = dp.standardize(train_y)\n",
    "    train_X_scale = train_X_scale.reshape(-1, time_step, feature_num)\n",
    "\n",
    "    test_X = dp.make_slide_windows(etf_df.iloc[-(time_step-1+shift_range):], time_step)\n",
    "    # 符合 scaler dim\n",
    "    test_X_scale = scaler_X.transform(test_X)\n",
    "    test_X_scale = test_X_scale.reshape(-1, time_step, feature_num)\n",
    "    print(\"train_X_scale: {}, train_y_scale: {}, test_X_scale: {}\".format(train_X_scale.shape, train_y_scale.shape, test_X_scale.shape))\n",
    "    # train model\n",
    "    model = Sequential()\n",
    "    model.add(GRU(40, input_shape=(time_step, feature_num)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    model.summary()\n",
    "    model.fit(\n",
    "        train_X_scale, train_y_scale, epochs=40, \n",
    "        batch_size=32, verbose=1, validation_split=0.2)\n",
    "    # predict\n",
    "    pred = scaler_y.inverse_transform(model.predict(test_X_scale))\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_submission(df, method, add_stock_feature=False):\n",
    "    submission_list = []\n",
    "    fe = FeatureExtraction()\n",
    "    util = Util()\n",
    "    etf_code_list = list(df.groupby(df['code']).size().index)\n",
    "    for etf_code in etf_code_list:\n",
    "        etf_df = df.loc[df['code']==etf_code,:]\n",
    "        # set to time index\n",
    "        select_columns = ['open', 'high', 'low', 'close','volume', 'adj close']\n",
    "        etf_df = etf_df.loc[:,select_columns].set_index(etf_df['date'])\n",
    "        # extract stock features\n",
    "        if add_stock_feature:\n",
    "            etf_df = fe.perform_stock_stat(etf_df)\n",
    "        method_dict = {\n",
    "            'linear regression': perform_linear_regression,\n",
    "            'xgboost': perform_xgboost,\n",
    "            'ARIMA': perform_ARIMA,\n",
    "            'RNN many to many': perform_RNN_many_to_many,\n",
    "            'RNN many to one': perform_RNN_many_to_one\n",
    "        }\n",
    "        pred = method_dict.get(method)(etf_df)\n",
    "        pred = pred.flatten()\n",
    "        submission_record = util.make_submission_record(etf_code, etf_df, pred)\n",
    "        submission_list.append(submission_record)\n",
    "    submission_df = pd.DataFrame(data=submission_list, columns=[\n",
    "        'ETFid','Mon_ud', 'Mon_cprice', 'Tue_ud', 'Tue_cprice', 'Wed_ud', 'Wed_cprice',\n",
    "        'Thu_ud', 'Thu_cprice', 'Fri_ud', 'Fri_cprice'\n",
    "    ])\n",
    "    return submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_formula(t_ud, s_ud, t_p, s_p):\n",
    "    return (0.5 if t_ud == s_ud else 0) + ((t_p-abs(s_p-t_p))/t_p)*0.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_point(sub_df, true_df):\n",
    "    \"\"\"\n",
    "    漲跌: 預測正確得0.5\n",
    "    價格: (實際價格 – 絕對值(預測價格 – 實際價格)) /實際價格)*0.5) , 也就預測越正確, 越接近 0.5 分數權重\n",
    "    週一: 10%\n",
    "    週二: 15%\n",
    "    週三: 20%\n",
    "    週四: 25%\n",
    "    週五: 30%\n",
    "    \"\"\"\n",
    "    true_ud_df = true_df.loc[:,true_df.columns.str.contains('ud')]\n",
    "    sub_ud_df = sub_df.loc[:,sub_df.columns.str.contains('ud')]\n",
    "    \n",
    "    true_price_df = true_df.loc[:,true_df.columns.str.contains('price')]\n",
    "    sub_price_df = sub_df.loc[:,sub_df.columns.str.contains('price')]\n",
    "    total_value = 0\n",
    "    for t_ud, s_ud, t_p, s_p in zip(true_ud_df.values, sub_ud_df.values, true_price_df.values, sub_price_df.values):\n",
    "        mon_point = point_formula(t_ud[0], s_ud[0], t_p[0], s_p[0]) * 0.1\n",
    "        tue_point = point_formula(t_ud[1], s_ud[1], t_p[1], s_p[1]) * 0.15\n",
    "        wed_point = point_formula(t_ud[2], s_ud[2], t_p[2], s_p[2]) * 0.2\n",
    "        thu_point = point_formula(t_ud[3], s_ud[3], t_p[3], s_p[3]) * 0.25\n",
    "        fri_point = point_formula(t_ud[4], s_ud[4], t_p[4], s_p[4]) * 0.30\n",
    "        total_value += (mon_point + tue_point + wed_point + thu_point + fri_point)\n",
    "    return total_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect predict result\n",
    "def eval_points_by_method(df, method, train_count=None, add_stock_feature=False):\n",
    "    submission_list = []\n",
    "    ground_true_list = []\n",
    "    fe = FeatureExtraction()\n",
    "    etf_code_list = list(df.groupby(df['code']).size().index)\n",
    "    for etf_code in etf_code_list:\n",
    "        etf_df = df.loc[df['code']==etf_code,:]\n",
    "        # set to time index\n",
    "        select_columns = ['open', 'high', 'low', 'close','volume', 'adj close']\n",
    "        etf_df = etf_df.loc[:,select_columns].set_index(etf_df['date'])\n",
    "        # stock feature\n",
    "        if add_stock_feature:\n",
    "            etf_df = fe.perform_stock_stat(etf_df)\n",
    "        if train_count:\n",
    "            etf_df = etf_df.tail(train_count)\n",
    "        train_df = etf_df.iloc[:-5,]\n",
    "        test_df = etf_df.iloc[-5:,]\n",
    "        test_y = test_df['adj close'].values\n",
    "\n",
    "        method_dict = {\n",
    "            'linear regression': perform_linear_regression,\n",
    "            'ARIMA': perform_ARIMA,\n",
    "            'xgboost': perform_xgboost,\n",
    "            'RNN many to many': perform_RNN_many_to_many,\n",
    "            'RNN many to one': perform_RNN_many_to_one,\n",
    "            'prophet': perform_prophet\n",
    "        }\n",
    "        pred = method_dict.get(method)(train_df)\n",
    "        pred = pred.flatten()\n",
    "        submission_record = util.make_submission_record(etf_code, train_df, pred)\n",
    "        ground_true_record = util.make_submission_record(etf_code, train_df, test_y)\n",
    "        submission_list.append(submission_record)\n",
    "        ground_true_list.append(ground_true_record)\n",
    "    sub_col = [\n",
    "        'ETFid','Mon_ud', 'Mon_cprice', 'Tue_ud', 'Tue_cprice', 'Wed_ud', 'Wed_cprice',\n",
    "        'Thu_ud', 'Thu_cprice', 'Fri_ud', 'Fri_cprice'\n",
    "    ]\n",
    "    submission_df = pd.DataFrame(data=submission_list, columns=sub_col)\n",
    "    ground_true_df = pd.DataFrame(data=ground_true_list, columns=sub_col)\n",
    "    return evaluate_point(submission_df, ground_true_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = 'csv/TBrain_Round2_DataSet_20180601/'\n",
    "csv_list = os.listdir(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tasharep.csv', 'tetfp.csv', 'taetfp.csv', 'tsharep.csv']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write CSV to mongoDB\n",
    "# mongo = MongoBase('mongodb://220.133.208.31:27017/', 'test-database')\n",
    "# for csv_name in csv_list:\n",
    "#     df = pd.read_csv('csv/' + csv_name, encoding='cp950', dtype='str')\n",
    "#     collection_name = csv_name.split('.')[0]\n",
    "#     mongo.insert_document(collection_name, etf_data_preprocess(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tetfp: 18 檔 ETF\n",
    "# taetfp: 調整後 18 檔 ETF \n",
    "# tsharep: 個股\n",
    "# tasharep: 調整後個股\n",
    "\n",
    "df = pd.read_csv(csv_path + 'tetfp.csv', encoding='cp950', dtype='str')\n",
    "util = Util()\n",
    "df = util.etf_data_preprocess(df)\n",
    "adj_closed = pd.read_csv(csv_path + 'taetfp.csv', encoding='cp950', dtype='str')['收盤價(元)']\n",
    "adj_closed = adj_closed.astype('float64').values\n",
    "colname_mapping = {\n",
    "    '代碼': 'code', '日期': 'date', '中文簡稱': 'chinese', '開盤價(元)': 'open',\n",
    "    '最高價(元)': 'high', '最低價(元)': 'low', '收盤價(元)': 'close', '成交張數(張)': 'volume'\n",
    "}\n",
    "df.rename(index=str, columns=colname_mapping, inplace=True)\n",
    "df['adj close'] = adj_closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "code\n",
       "0050      1327\n",
       "0051      1327\n",
       "0052      1327\n",
       "0053      1327\n",
       "0054      1327\n",
       "0055      1327\n",
       "0056      1327\n",
       "0057      1327\n",
       "0058      1327\n",
       "0059      1327\n",
       "006201    1327\n",
       "006203    1327\n",
       "006204    1327\n",
       "006208    1327\n",
       "00690      289\n",
       "00692      259\n",
       "00701      194\n",
       "00713      165\n",
       "dtype: int64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 資料分布屬性\n",
    "df.groupby(df['code']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear_regression train df shape: (1317, 7)\n",
      "linear_regression train df shape: (1317, 7)\n",
      "linear_regression train df shape: (1317, 7)\n",
      "linear_regression train df shape: (1317, 7)\n",
      "linear_regression train df shape: (1317, 7)\n",
      "linear_regression train df shape: (1317, 7)\n",
      "linear_regression train df shape: (1317, 7)\n",
      "linear_regression train df shape: (1317, 7)\n",
      "linear_regression train df shape: (1317, 7)\n",
      "linear_regression train df shape: (1317, 7)\n",
      "linear_regression train df shape: (1317, 7)\n",
      "linear_regression train df shape: (1317, 7)\n",
      "linear_regression train df shape: (1317, 7)\n",
      "linear_regression train df shape: (1317, 7)\n",
      "linear_regression train df shape: (279, 7)\n",
      "linear_regression train df shape: (249, 7)\n",
      "linear_regression train df shape: (184, 7)\n",
      "linear_regression train df shape: (155, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14.386108039023279"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "method_list = ['linear regression', 'ARIMA', 'RNN many to many', 'RNN many to one', 'xgboost']\n",
    "eval_points_by_method(df, method_list[0])\n",
    "submission_df = make_submission(df, method_list[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ETFid</th>\n",
       "      <th>Mon_ud</th>\n",
       "      <th>Mon_cprice</th>\n",
       "      <th>Tue_ud</th>\n",
       "      <th>Tue_cprice</th>\n",
       "      <th>Wed_ud</th>\n",
       "      <th>Wed_cprice</th>\n",
       "      <th>Thu_ud</th>\n",
       "      <th>Thu_cprice</th>\n",
       "      <th>Fri_ud</th>\n",
       "      <th>Fri_cprice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>81.910004</td>\n",
       "      <td>-1</td>\n",
       "      <td>81.699997</td>\n",
       "      <td>-1</td>\n",
       "      <td>80.870003</td>\n",
       "      <td>-1</td>\n",
       "      <td>80.699997</td>\n",
       "      <td>1</td>\n",
       "      <td>81.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51</td>\n",
       "      <td>-1</td>\n",
       "      <td>33.709999</td>\n",
       "      <td>-1</td>\n",
       "      <td>33.709999</td>\n",
       "      <td>-1</td>\n",
       "      <td>33.700001</td>\n",
       "      <td>1</td>\n",
       "      <td>33.750000</td>\n",
       "      <td>-1</td>\n",
       "      <td>33.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>52.040001</td>\n",
       "      <td>-1</td>\n",
       "      <td>51.950001</td>\n",
       "      <td>1</td>\n",
       "      <td>51.950001</td>\n",
       "      <td>1</td>\n",
       "      <td>51.950001</td>\n",
       "      <td>1</td>\n",
       "      <td>51.950001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>-1</td>\n",
       "      <td>35.700001</td>\n",
       "      <td>1</td>\n",
       "      <td>35.799999</td>\n",
       "      <td>-1</td>\n",
       "      <td>35.459999</td>\n",
       "      <td>1</td>\n",
       "      <td>35.730000</td>\n",
       "      <td>-1</td>\n",
       "      <td>35.560001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>-1</td>\n",
       "      <td>24.020000</td>\n",
       "      <td>1</td>\n",
       "      <td>24.030001</td>\n",
       "      <td>-1</td>\n",
       "      <td>23.990000</td>\n",
       "      <td>1</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>24.040001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>17.389999</td>\n",
       "      <td>-1</td>\n",
       "      <td>17.389999</td>\n",
       "      <td>1</td>\n",
       "      <td>17.450001</td>\n",
       "      <td>-1</td>\n",
       "      <td>17.410000</td>\n",
       "      <td>1</td>\n",
       "      <td>17.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>56</td>\n",
       "      <td>-1</td>\n",
       "      <td>26.139999</td>\n",
       "      <td>1</td>\n",
       "      <td>26.170000</td>\n",
       "      <td>1</td>\n",
       "      <td>26.219999</td>\n",
       "      <td>1</td>\n",
       "      <td>26.340000</td>\n",
       "      <td>-1</td>\n",
       "      <td>25.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>50.080002</td>\n",
       "      <td>1</td>\n",
       "      <td>50.509998</td>\n",
       "      <td>-1</td>\n",
       "      <td>49.250000</td>\n",
       "      <td>-1</td>\n",
       "      <td>48.869999</td>\n",
       "      <td>1</td>\n",
       "      <td>50.270000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>58</td>\n",
       "      <td>-1</td>\n",
       "      <td>46.900002</td>\n",
       "      <td>1</td>\n",
       "      <td>47.160000</td>\n",
       "      <td>-1</td>\n",
       "      <td>46.520000</td>\n",
       "      <td>1</td>\n",
       "      <td>47.130001</td>\n",
       "      <td>-1</td>\n",
       "      <td>46.959999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>42.500000</td>\n",
       "      <td>-1</td>\n",
       "      <td>42.400002</td>\n",
       "      <td>1</td>\n",
       "      <td>42.400002</td>\n",
       "      <td>-1</td>\n",
       "      <td>41.439999</td>\n",
       "      <td>1</td>\n",
       "      <td>41.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6201</td>\n",
       "      <td>1</td>\n",
       "      <td>14.760000</td>\n",
       "      <td>-1</td>\n",
       "      <td>14.310000</td>\n",
       "      <td>1</td>\n",
       "      <td>14.420000</td>\n",
       "      <td>-1</td>\n",
       "      <td>14.110000</td>\n",
       "      <td>1</td>\n",
       "      <td>14.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6203</td>\n",
       "      <td>1</td>\n",
       "      <td>37.990002</td>\n",
       "      <td>-1</td>\n",
       "      <td>37.959999</td>\n",
       "      <td>-1</td>\n",
       "      <td>37.779999</td>\n",
       "      <td>1</td>\n",
       "      <td>37.939999</td>\n",
       "      <td>1</td>\n",
       "      <td>38.150002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6204</td>\n",
       "      <td>-1</td>\n",
       "      <td>54.360001</td>\n",
       "      <td>-1</td>\n",
       "      <td>54.130001</td>\n",
       "      <td>-1</td>\n",
       "      <td>53.880001</td>\n",
       "      <td>1</td>\n",
       "      <td>54.009998</td>\n",
       "      <td>1</td>\n",
       "      <td>54.240002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6208</td>\n",
       "      <td>1</td>\n",
       "      <td>47.869999</td>\n",
       "      <td>1</td>\n",
       "      <td>47.950001</td>\n",
       "      <td>-1</td>\n",
       "      <td>47.099998</td>\n",
       "      <td>-1</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>47.060001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>690</td>\n",
       "      <td>1</td>\n",
       "      <td>22.110001</td>\n",
       "      <td>-1</td>\n",
       "      <td>22.030001</td>\n",
       "      <td>-1</td>\n",
       "      <td>21.860001</td>\n",
       "      <td>1</td>\n",
       "      <td>21.870001</td>\n",
       "      <td>1</td>\n",
       "      <td>21.889999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>692</td>\n",
       "      <td>1</td>\n",
       "      <td>21.620001</td>\n",
       "      <td>-1</td>\n",
       "      <td>21.320000</td>\n",
       "      <td>1</td>\n",
       "      <td>21.459999</td>\n",
       "      <td>-1</td>\n",
       "      <td>21.209999</td>\n",
       "      <td>1</td>\n",
       "      <td>21.219999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>701</td>\n",
       "      <td>-1</td>\n",
       "      <td>20.980000</td>\n",
       "      <td>1</td>\n",
       "      <td>21.170000</td>\n",
       "      <td>-1</td>\n",
       "      <td>20.910000</td>\n",
       "      <td>1</td>\n",
       "      <td>21.160000</td>\n",
       "      <td>-1</td>\n",
       "      <td>21.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>713</td>\n",
       "      <td>1</td>\n",
       "      <td>31.230000</td>\n",
       "      <td>-1</td>\n",
       "      <td>30.600000</td>\n",
       "      <td>-1</td>\n",
       "      <td>30.510000</td>\n",
       "      <td>1</td>\n",
       "      <td>30.950001</td>\n",
       "      <td>-1</td>\n",
       "      <td>30.840000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ETFid  Mon_ud  Mon_cprice  Tue_ud  Tue_cprice  Wed_ud  Wed_cprice  Thu_ud  \\\n",
       "0      50       1   81.910004      -1   81.699997      -1   80.870003      -1   \n",
       "1      51      -1   33.709999      -1   33.709999      -1   33.700001       1   \n",
       "2      52       1   52.040001      -1   51.950001       1   51.950001       1   \n",
       "3      53      -1   35.700001       1   35.799999      -1   35.459999       1   \n",
       "4      54      -1   24.020000       1   24.030001      -1   23.990000       1   \n",
       "5      55       1   17.389999      -1   17.389999       1   17.450001      -1   \n",
       "6      56      -1   26.139999       1   26.170000       1   26.219999       1   \n",
       "7      57       1   50.080002       1   50.509998      -1   49.250000      -1   \n",
       "8      58      -1   46.900002       1   47.160000      -1   46.520000       1   \n",
       "9      59       1   42.500000      -1   42.400002       1   42.400002      -1   \n",
       "10   6201       1   14.760000      -1   14.310000       1   14.420000      -1   \n",
       "11   6203       1   37.990002      -1   37.959999      -1   37.779999       1   \n",
       "12   6204      -1   54.360001      -1   54.130001      -1   53.880001       1   \n",
       "13   6208       1   47.869999       1   47.950001      -1   47.099998      -1   \n",
       "14    690       1   22.110001      -1   22.030001      -1   21.860001       1   \n",
       "15    692       1   21.620001      -1   21.320000       1   21.459999      -1   \n",
       "16    701      -1   20.980000       1   21.170000      -1   20.910000       1   \n",
       "17    713       1   31.230000      -1   30.600000      -1   30.510000       1   \n",
       "\n",
       "    Thu_cprice  Fri_ud  Fri_cprice  \n",
       "0    80.699997       1   81.320000  \n",
       "1    33.750000      -1   33.520000  \n",
       "2    51.950001       1   51.950001  \n",
       "3    35.730000      -1   35.560001  \n",
       "4    24.000000       1   24.040001  \n",
       "5    17.410000       1   17.480000  \n",
       "6    26.340000      -1   25.910000  \n",
       "7    48.869999       1   50.270000  \n",
       "8    47.130001      -1   46.959999  \n",
       "9    41.439999       1   41.770000  \n",
       "10   14.110000       1   14.320000  \n",
       "11   37.939999       1   38.150002  \n",
       "12   54.009998       1   54.240002  \n",
       "13   47.000000       1   47.060001  \n",
       "14   21.870001       1   21.889999  \n",
       "15   21.209999       1   21.219999  \n",
       "16   21.160000      -1   21.020000  \n",
       "17   30.950001      -1   30.840000  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('result.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
